# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mG8qKuOqCkkeXVRQKFK3ia4PdmlhBBUF
"""

from fastapi import FastAPI, Query
from pydantic import BaseModel
import torch
from transformers import BertTokenizer, BertForSequenceClassification
from torch.nn.functional import softmax

app = FastAPI(
    title="CitiSnap Sentiment Analysis API",
    description="Lokal Deploy Citisnap API untuk prediksi sentimen",
    version="1.0.0",
    openapi_url="/openapi.json",
    docs_url="/docs",
)

# Load the model and tokenizer
model_path = 'C:\\Users\\alias\\OneDrive\\Documents\\citisnap'  # Ganti dengan path sesuai lokasi penyimpanan model
tokenizer_path = 'C:\\Users\\alias\\OneDrive\\Documents\\citisnap'  # Ganti dengan path sesuai lokasi penyimpanan tokenizer

tokenizer = BertTokenizer.from_pretrained(tokenizer_path)
model = BertForSequenceClassification.from_pretrained(model_path)

i2w = {"0": "negative", "1": "neutral", "2": "positive"}

# Ensure that the model is on the same device as the input data
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

class SentimentRequest(BaseModel):
    text: str

@app.post("/predict")
def predict_sentiment(request: SentimentRequest):
    text = request.text
    subwords = tokenizer.encode(text)
    subwords = torch.LongTensor(subwords).view(1, -1).to(device)

    logits = model(subwords)[0]
    label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()
    probability = softmax(logits, dim=-1).squeeze()[label].item()

    return {"text": text, "sentiment": i2w[label], "probability": probability}